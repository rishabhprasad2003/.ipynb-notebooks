{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D18.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmRV8ehqokNwg3FKsXRQRj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishabhprasad2003/.ipynb-notebooks/blob/main/Notebooks/D18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5nGqWQeN6X6"
      },
      "outputs": [],
      "source": [
        "#18. CLICK BUTTON PROJECT\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#create a black image and a window\n",
        "windowName = 'Drawing'\n",
        "cv2.namedWindow(windowName)\n",
        "img = np.zeros((500,500,3))\n",
        "\n",
        "#mouse callback function\n",
        "#flags and param are not used at all, but we need to write it in any mousecall back fnuction\n",
        "def draw_circle(event,x,y,flags,param):\n",
        "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
        "        cv2.circle(img,(x,y),40,(0,255,0),-1)\n",
        "\n",
        "    if event == cv2.EVENT_RBUTTONDBLCLK: #right button double double click\n",
        "        cv2.circle(img,(x,y),30,(255,255,255),-1)\n",
        "\n",
        "    if event == cv2.EVENT_LBUTTONDOWN:  #left button\n",
        "        cv2.circle(img,(x,y),20,(0,255,255),-1)\n",
        "\n",
        "    if event == cv2.EVENT_RBUTTONDOWN: #right click\n",
        "        cv2.circle(img,(x,y),10,(0,0,255),-1)\n",
        "\n",
        "cv2.setMouseCallback(windowName,draw_circle)  #function call\n",
        "while(True):\n",
        "    cv2.imshow(windowName,img)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#19. ACCESSING THE WEBCAM USING PYTHON AND OPENCV\n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# 0 takes the default camera out of laptop\n",
        "# 1 take the webcam in case of a Pc\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read() # it is reading the video from my port\n",
        "    #ret and frame are 2 variable to be taken, but only frame will be used\n",
        "    #ret is dummy variable\n",
        "    cv2.imshow('My Live Sketch',frame)\n",
        "    if cv2.waitKey(1) == 13:  #13 is the ASCII value for 'enter' key\n",
        "        break\n",
        "\n",
        "cap.release()  # It releases the port number\n",
        "#make sure we perform cap.release, if not the webcam drivers may get corrupted\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "bCy27esJWYNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. MY CANNY SKETCH(EDGE DETECTION)\n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret,frame = cap.read()\n",
        "    canny = cv2.Canny(frame,20,150)  #20,150 are thresh values for best canny\n",
        "    cv2.imshow('MY CANNY SKEYCH',canny)\n",
        "    if cv2.waitKey(1) == 13:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "beBWvivUaH9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21. FACE RECOGNITION\n",
        "\n",
        "import cv2\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "img = cv2.imread('abc.jpg')  #reading the image\n",
        "\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #will convert the image into grayscale\n",
        "\n",
        "faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.1,minNeighbors = 9)\n",
        "#scaleFactor and minNeighbors are the tuning parameters\n",
        "\n",
        "for x,y,w,h in faces:\n",
        "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),5)\n",
        "    #w and h are height and width\n",
        "\n",
        "cv2.imshow('FACE RECOGNITION',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "LDuoEI7weX4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xnucKBxujo5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}